workflow:
  rules:
    - if: $CI_COMMIT_BRANCH == "main"

default:
  image:
    name: alpine:3.18
  before_script:
    - apk add terraform python3 py3-pip openssh --no-cache
    - terraform init -upgrade -backend-config="password=${CI_JOB_TOKEN}"

stages:
  - plan
  - apply
  - ansible
  - destroy

plan:
  stage: plan
  before_script:
    - apk add terraform --no-cache
    - cd ${CI_PROJECT_DIR}/terraform
    - terraform init -upgrade -backend-config="password=${CI_JOB_TOKEN}"
  script:
    - terraform fmt
    - terraform validate
    - terraform plan

apply:
  stage: apply
  before_script:
    - apk add terraform --no-cache
    - cd ${CI_PROJECT_DIR}/terraform
    - terraform init -upgrade -backend-config="password=${CI_JOB_TOKEN}"
  script:
    - terraform apply -auto-approve
  allow_failure: true
  artifacts:
    paths:
      - terraform/tf_ansible_vars_file.yml
  when: manual

ansible:
  stage: ansible
  before_script:
    - apk add terraform openssh ansible --no-cache
    - cd ${CI_PROJECT_DIR}/terraform
    - terraform init -upgrade -backend-config="password=${CI_JOB_TOKEN}"
    - terraform apply -target=local_file.ansible_inventory -auto-approve
  script:
    - cd ${CI_PROJECT_DIR}/terraform
    - export TF_VAR_fixed_ip=$(terraform output -raw host_fixed_ip)
    - cd ${CI_PROJECT_DIR}/ansible
    - ls
    - echo "$SSH_PRIVATE_KEY" > ssh_key_file
    - chmod 600 ssh_key_file
    - ANSIBLE_HOST_KEY_CHECKING=false ansible-playbook -i inventory.yaml host.yaml --key-file ssh_key_file
    - ANSIBLE_HOST_KEY_CHECKING=false ansible-playbook -i inventory.yaml guests.yaml --key-file ssh_key_file
  allow_failure: true
  when: manual

destroy:
  stage: destroy
  before_script:
    - apk add terraform --no-cache
    - cd ${CI_PROJECT_DIR}/terraform
    - terraform init -upgrade -reconfigure -backend-config="password=${CI_JOB_TOKEN}"
  script:
    - terraform destroy -auto-approve
  when: manual
